{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('course_lead_scoring.csv')\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "categorical_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "for c in categorical_columns:\n",
    "    df[c] = df[c].str.lower().str.replace(' ', '_')\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: What is the mode of the `industry` variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'retail'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['industry'].mode()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: What are the two features that have the biggest correlation?\n",
    "\n",
    "Create the correlation matrix for the numerical features. Check these pairs:\n",
    "- interaction_count and lead_score\n",
    "- number_of_courses_viewed and lead_score\n",
    "- number_of_courses_viewed and interaction_count\n",
    "- annual_income and interaction_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix:\n",
      "                          number_of_courses_viewed  annual_income  \\\n",
      "number_of_courses_viewed                  1.000000       0.009770   \n",
      "annual_income                             0.009770       1.000000   \n",
      "interaction_count                        -0.023565       0.027036   \n",
      "lead_score                               -0.004879       0.015610   \n",
      "\n",
      "                          interaction_count  lead_score  \n",
      "number_of_courses_viewed          -0.023565   -0.004879  \n",
      "annual_income                      0.027036    0.015610  \n",
      "interaction_count                  1.000000    0.009888  \n",
      "lead_score                         0.009888    1.000000  \n",
      "\n",
      "==================================================\n",
      "\n",
      "Correlation for specific pairs:\n",
      "interaction_count and lead_score: 0.009888\n",
      "number_of_courses_viewed and lead_score: -0.004879\n",
      "number_of_courses_viewed and interaction_count: -0.023565\n",
      "annual_income and interaction_count: 0.027036\n",
      "\n",
      "The pair with the biggest correlation: annual_income and interaction_count (0.027036)\n"
     ]
    }
   ],
   "source": [
    "# Identify numerical features\n",
    "numerical_features = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
    "\n",
    "# Create correlation matrix\n",
    "corr_matrix = df[numerical_features].corr()\n",
    "print(\"Correlation Matrix:\")\n",
    "print(corr_matrix)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Check the specific pairs mentioned in the question\n",
    "pairs = [\n",
    "    ('interaction_count', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'interaction_count'),\n",
    "    ('annual_income', 'interaction_count')\n",
    "]\n",
    "\n",
    "print(\"Correlation for specific pairs:\")\n",
    "for feature1, feature2 in pairs:\n",
    "    correlation = corr_matrix.loc[feature1, feature2]\n",
    "    print(f\"{feature1} and {feature2}: {correlation:.6f}\")\n",
    "\n",
    "# Find the pair with the highest correlation\n",
    "max_corr = 0\n",
    "max_pair = None\n",
    "for feature1, feature2 in pairs:\n",
    "    correlation = abs(corr_matrix.loc[feature1, feature2])\n",
    "    if correlation > max_corr:\n",
    "        max_corr = correlation\n",
    "        max_pair = (feature1, feature2)\n",
    "\n",
    "print(f\"\\nThe pair with the biggest correlation: {max_pair[0]} and {max_pair[1]} ({corr_matrix.loc[max_pair[0], max_pair[1]]:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Which categorical variable has the biggest mutual information score?\n",
    "\n",
    "Calculate the mutual information score between y and other categorical variables using the training set only. Round scores to 2 decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "industry: 0.01\n",
      "location: 0.0\n",
      "lead_source: 0.02\n",
      "employment_status: 0.02\n",
      "\n",
      "The variable with the biggest mutual information score: lead_source (0.02)\n"
     ]
    }
   ],
   "source": [
    "# Calculate mutual information score for each categorical variable\n",
    "categorical_vars = ['industry', 'location', 'lead_source', 'employment_status']\n",
    "\n",
    "mi_scores = {}\n",
    "for var in categorical_vars:\n",
    "    score = mutual_info_score(df_train[var].astype(str), y_train.astype(str))\n",
    "    mi_scores[var] = round(score, 2)\n",
    "    print(f\"{var}: {mi_scores[var]}\")\n",
    "\n",
    "# Find the variable with the highest MI score\n",
    "max_var = max(mi_scores, key=mi_scores.get)\n",
    "print(f\"\\nThe variable with the biggest mutual information score: {max_var} ({mi_scores[max_var]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Split the data into train/val/test sets with 60%/20%/20% distribution using seed 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 877 (60.0%)\n",
      "Val size: 292 (20.0%)\n",
      "Test size: 293 (20.0%)\n",
      "\n",
      "Target distribution:\n",
      "Train: 535 converted out of 877 (61.0%)\n",
      "Val: 197 converted out of 292 (67.5%)\n",
      "Test: 173 converted out of 293 (59.0%)\n"
     ]
    }
   ],
   "source": [
    "# Split data: 60% train, 20% val, 20% test with seed 42\n",
    "# First split: 60% train, 40% temp (val + test)\n",
    "df_train, df_temp = train_test_split(df, test_size=0.4, random_state=42)\n",
    "\n",
    "# Second split: split the 40% into 50/50 (20% val, 20% test)\n",
    "df_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reset indices\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "print(f\"Train size: {len(df_train)} ({len(df_train)/len(df)*100:.1f}%)\")\n",
    "print(f\"Val size: {len(df_val)} ({len(df_val)/len(df)*100:.1f}%)\")\n",
    "print(f\"Test size: {len(df_test)} ({len(df_test)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Extract target variable y\n",
    "y_train = df_train.converted.values\n",
    "y_val = df_val.converted.values\n",
    "y_test = df_test.converted.values\n",
    "\n",
    "# Remove target variable from dataframes\n",
    "del df_train['converted']\n",
    "del df_val['converted']\n",
    "del df_test['converted']\n",
    "\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(f\"Train: {y_train.sum()} converted out of {len(y_train)} ({y_train.mean()*100:.1f}%)\")\n",
    "print(f\"Val: {y_val.sum()} converted out of {len(y_val)} ({y_val.mean()*100:.1f}%)\")\n",
    "print(f\"Test: {y_test.sum()} converted out of {len(y_test)} ({y_test.mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: What's the accuracy on the validation dataset?\n",
    "\n",
    "Train a logistic regression model with one-hot encoding for categorical variables. Use these parameters for reproducibility:\n",
    "- solver='liblinear'\n",
    "- C=1.0\n",
    "- max_iter=1000\n",
    "- random_state=42\n",
    "\n",
    "Round the accuracy to 2 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7431506849315068\n",
      "Validation accuracy (rounded to 2 decimals): 0.74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.74"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define features\n",
    "numerical = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
    "categorical = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "\n",
    "# One-hot encoding using DictVectorizer\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "# Prepare training data\n",
    "train_dict = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "# Train logistic regression model with specified parameters\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prepare validation data\n",
    "val_dict = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)\n",
    "\n",
    "# Calculate accuracy on validation set\n",
    "y_pred = model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print(f\"Validation accuracy: {accuracy}\")\n",
    "print(f\"Validation accuracy (rounded to 2 decimals): {round(accuracy, 2)}\")\n",
    "\n",
    "round(accuracy, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: Which feature has the smallest difference?\n",
    "\n",
    "Find the least useful feature using feature elimination technique:\n",
    "1. Train a model with all features (same parameters as Q4, without rounding)\n",
    "2. Exclude each feature one at a time and train a model without it\n",
    "3. Record the accuracy for each model\n",
    "4. Calculate the difference: (original accuracy - accuracy without feature)\n",
    "\n",
    "Which of these features has the smallest difference?\n",
    "- 'industry'\n",
    "- 'employment_status'\n",
    "- 'lead_score'\n",
    "\n",
    "Note: The difference doesn't have to be positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy (with all features): 0.7431506849315068\n",
      "\n",
      "============================================================\n",
      "Without 'lead_source': accuracy=0.732877, diff=0.010274\n",
      "Without 'industry': accuracy=0.743151, diff=0.000000\n",
      "Without 'employment_status': accuracy=0.746575, diff=-0.003425\n",
      "Without 'location': accuracy=0.743151, diff=0.000000\n",
      "Without 'number_of_courses_viewed': accuracy=0.678082, diff=0.065068\n",
      "Without 'annual_income': accuracy=0.852740, diff=-0.109589\n",
      "Without 'interaction_count': accuracy=0.674658, diff=0.068493\n",
      "Without 'lead_score': accuracy=0.743151, diff=0.000000\n",
      "\n",
      "============================================================\n",
      "\n",
      "Focus on the three specific features:\n",
      "'industry': difference = 0.000000\n",
      "'employment_status': difference = -0.003425\n",
      "'lead_score': difference = 0.000000\n",
      "\n",
      "Feature with smallest difference: 'industry' (0.000000)\n"
     ]
    }
   ],
   "source": [
    "# Define all features\n",
    "numerical = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
    "categorical = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "all_features = categorical + numerical\n",
    "\n",
    "# Train baseline model with all features (same as Q4)\n",
    "dv = DictVectorizer(sparse=False)\n",
    "train_dict = df_train[all_features].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "val_dict = df_val[all_features].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)\n",
    "y_pred = model.predict(X_val)\n",
    "baseline_accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print(f\"Baseline accuracy (with all features): {baseline_accuracy}\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train models excluding each feature one at a time\n",
    "accuracies_without = {}\n",
    "differences = {}\n",
    "\n",
    "for feature in all_features:\n",
    "    # Create subset excluding current feature\n",
    "    subset = [f for f in all_features if f != feature]\n",
    "    \n",
    "    # Train model without this feature\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    train_dict = df_train[subset].to_dict(orient='records')\n",
    "    X_train = dv.fit_transform(train_dict)\n",
    "    \n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    val_dict = df_val[subset].to_dict(orient='records')\n",
    "    X_val = dv.transform(val_dict)\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    accuracy_without = accuracy_score(y_val, y_pred)\n",
    "    accuracies_without[feature] = accuracy_without\n",
    "    \n",
    "    # Calculate difference: original - without\n",
    "    diff = baseline_accuracy - accuracy_without\n",
    "    differences[feature] = diff\n",
    "    \n",
    "    print(f\"Without '{feature}': accuracy={accuracy_without:.6f}, diff={diff:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nFocus on the three specific features:\")\n",
    "for feature in ['industry', 'employment_status', 'lead_score']:\n",
    "    print(f\"'{feature}': difference = {differences[feature]:.6f}\")\n",
    "\n",
    "# Find feature with smallest difference among the three\n",
    "target_features = ['industry', 'employment_status', 'lead_score']\n",
    "min_diff_feature = min(target_features, key=lambda x: abs(differences[x]))\n",
    "print(f\"\\nFeature with smallest difference: '{min_diff_feature}' ({differences[min_diff_feature]:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: Which C parameter leads to the best accuracy?\n",
    "\n",
    "Train regularized logistic regression models with different C values: [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "Use all features as in Q4 with the same parameters (except varying C).\n",
    "Calculate the accuracy on the validation dataset and round it to 3 decimal digits.\n",
    "\n",
    "Which C leads to the best accuracy on the validation set?\n",
    "- 0.01\n",
    "- 0.1\n",
    "- 1\n",
    "- 10\n",
    "- 100\n",
    "\n",
    "Note: If there are multiple options with the same accuracy, select the smallest C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing different C values:\n",
      "============================================================\n",
      "C=  0.01: accuracy = 0.739726, rounded = 0.74\n",
      "C=   0.1: accuracy = 0.743151, rounded = 0.743\n",
      "C=     1: accuracy = 0.743151, rounded = 0.743\n",
      "C=    10: accuracy = 0.743151, rounded = 0.743\n",
      "C=   100: accuracy = 0.743151, rounded = 0.743\n",
      "\n",
      "============================================================\n",
      "\n",
      "Best accuracy: 0.743\n",
      "Best C: 0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define features (same as Q4)\n",
    "numerical = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
    "categorical = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "all_features = categorical + numerical\n",
    "\n",
    "# Prepare data with one-hot encoding\n",
    "dv = DictVectorizer(sparse=False)\n",
    "train_dict = df_train[all_features].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "val_dict = df_val[all_features].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)\n",
    "\n",
    "# Try different C values\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "results = {}\n",
    "\n",
    "print(\"Testing different C values:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for C in C_values:\n",
    "    # Train model with current C value\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict and calculate accuracy\n",
    "    y_pred = model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    \n",
    "    # Round to 3 decimal digits\n",
    "    accuracy_rounded = round(accuracy, 3)\n",
    "    results[C] = accuracy_rounded\n",
    "    \n",
    "    print(f\"C={C:>6}: accuracy = {accuracy:.6f}, rounded = {accuracy_rounded}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Find the best C (highest accuracy, smallest C if tied)\n",
    "max_accuracy = max(results.values())\n",
    "best_C = min([c for c, acc in results.items() if acc == max_accuracy])\n",
    "\n",
    "print(f\"\\nBest accuracy: {max_accuracy}\")\n",
    "print(f\"Best C: {best_C}\")\n",
    "\n",
    "best_C"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
